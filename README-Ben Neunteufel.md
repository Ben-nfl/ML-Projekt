# üç∑ Wine Quality - Vollst√§ndiges ML-Projekt

Ein umfassendes Machine-Learning-Projekt zur Vorhersage der Weinqualit√§t basierend auf physikalisch-chemischen Eigenschaften. Das Projekt enth√§lt sowohl ein detailliertes Jupyter Notebook f√ºr die Analyse als auch eine interaktive Streamlit-Webanwendung.

## üìã Inhaltsverzeichnis

- [Projekt√ºbersicht](#projekt√ºbersicht)
- [Dataset](#dataset)
- [Features](#features)
- [Installation](#installation)
- [Verwendung](#verwendung)
- [Projektstruktur](#projektstruktur)
- [Modelle](#modelle)
- [Ergebnisse](#ergebnisse)
- [Technologien](#technologien)

## üéØ Projekt√ºbersicht

Dieses Projekt analysiert den **Wine Quality Dataset** vom UCI Machine Learning Repository und entwickelt Vorhersagemodelle f√ºr die Weinqualit√§t. Es werden sowohl **Regression** (Vorhersage exakter Qualit√§tswerte) als auch **Klassifikation** (bin√§re Klassifikation: gut/schlecht) durchgef√ºhrt.

### Hauptziele:

1. Umfassende explorative Datenanalyse (EDA)
2. Feature Engineering und Datenbereinigung
3. Training und Evaluation mehrerer ML-Modelle
4. Hyperparameter-Optimierung
5. Interaktive Webanwendung zur Vorhersage

## üìä Dataset

**Quelle:** [UCI Machine Learning Repository - Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality)

**Beschreibung:**
- **Rotwein:** 1599 Samples
- **Wei√üwein:** 4898 Samples
- **Gesamt (kombiniert):** 6497 Samples (nach Duplikat-Entfernung)
- **Features:** 11 physikalisch-chemische Eigenschaften + 1 Weintyp
- **Zielvariable:** Qualit√§t (Skala 0-10, tats√§chlich 3-9)

### Features:

1. **fixed acidity** - Weins√§ure
2. **volatile acidity** - Fl√ºchtige S√§ure
3. **citric acid** - Zitronens√§ure
4. **residual sugar** - Restzucker
5. **chlorides** - Chloride
6. **free sulfur dioxide** - Freies Schwefeldioxid
7. **total sulfur dioxide** - Gesamtschwefeldioxid
8. **density** - Dichte
9. **pH** - pH-Wert
10. **sulphates** - Sulfate
11. **alcohol** - Alkoholgehalt
12. **wine_type** - Weintyp (0=Wei√üwein, 1=Rotwein)

### Engineered Features:

1. **free_to_total_sulfur_ratio** - Verh√§ltnis freies/gesamt Schwefel
2. **acid_ratio** - Verh√§ltnis Weins√§ure/fl√ºchtige S√§ure
3. **total_acidity** - Gesamts√§ure
4. **alcohol_per_acid** - Alkohol pro S√§ure
5. **quality_class** - Bin√§r (0=schlecht <6, 1=gut ‚â•6)

## ‚ú® Features

### Jupyter Notebook (`wine_quality_analysis.ipynb`)

- ‚úÖ Vollst√§ndiger Datenanalyse-Workflow
- ‚úÖ Umfassende Visualisierungen (Histogramme, Boxplots, Heatmaps, Scatterplots, Pairplots)
- ‚úÖ Ausrei√üer-Erkennung mit IQR-Methode
- ‚úÖ Korrelationsanalyse
- ‚úÖ Feature Engineering
- ‚úÖ 6 Regressionsmodelle:
  - Linear Regression
  - Ridge Regression
  - Random Forest Regressor
  - Gradient Boosting Regressor
  - K-Nearest Neighbors
  - Support Vector Regressor
- ‚úÖ 5 Klassifikationsmodelle:
  - Logistic Regression
  - Random Forest Classifier
  - Gradient Boosting Classifier
  - K-Nearest Neighbors
  - Support Vector Classifier
- ‚úÖ Hyperparameter-Tuning mit RandomizedSearchCV
- ‚úÖ Umfassende Evaluation:
  - Regression: RMSE, MAE, R¬≤
  - Klassifikation: Accuracy, Precision, Recall, F1, AUC, Confusion Matrix, ROC Curve
- ‚úÖ Feature Importance Analyse
- ‚úÖ Modellvergleich und Empfehlungen

### Streamlit App (`wine_quality_app.py`)

- ‚úÖ **Datenexploration:**
  - Interaktive Visualisierungen
  - Korrelationsmatrizen
  - Feature-Verteilungen
  - Scatter-Plots

- ‚úÖ **Modell Training:**
  - Auswahl zwischen Regression und Klassifikation
  - 6 verschiedene Modelltypen
  - Anpassbare Hyperparameter √ºber Sidebar
  - Live-Training und Evaluation
  - Visualisierung der Ergebnisse
  - Feature Importance Analyse
  - Modell-Export als .pkl Datei

- ‚úÖ **Vorhersage:**
  - Einzelne Vorhersage mit manuellen Eingaben
  - Batch-Vorhersage mit CSV-Upload
  - Visualisierung der Vorhersage-Konfidenz
  - Export der Ergebnisse

## üöÄ Installation

### Voraussetzungen

- Python 3.8 oder h√∂her
- pip (Python Package Manager)

### Schritt 1: Repository klonen oder herunterladen

```bash
cd /path/to/ML-Projekt
```

### Schritt 2: Virtual Environment erstellen (empfohlen)

```bash
# Virtual Environment erstellen
python -m venv venv

# Aktivieren (Windows)
venv\Scripts\activate

# Aktivieren (macOS/Linux)
source venv/bin/activate
```

### Schritt 3: Abh√§ngigkeiten installieren

```bash
pip install -r requirements.txt
```

## üíª Verwendung

### Jupyter Notebook

```bash
# Jupyter Notebook starten
jupyter notebook

# Dann √∂ffne: wine_quality_analysis.ipynb
```

F√ºhre alle Zellen sequenziell aus, um:
- Die Daten zu laden und zu analysieren
- Visualisierungen zu erstellen
- Modelle zu trainieren
- Ergebnisse zu evaluieren

### Streamlit App starten

```bash
streamlit run wine_quality_app.py
```

Die App √∂ffnet sich automatisch im Browser unter `http://localhost:8501`

### App-Navigation:

1. **üìä Datenexploration**
   - √úberblick √ºber den Datensatz
   - Statistische Zusammenfassung
   - Interaktive Visualisierungen
   - Korrelationsanalyse

2. **ü§ñ Modell Training**
   - W√§hle Aufgabentyp (Regression/Klassifikation)
   - W√§hle Modell aus Dropdown
   - Passe Hyperparameter an
   - Trainiere Modell
   - Evaluiere Performance
   - Speichere trainiertes Modell

3. **üîÆ Vorhersage**
   - Lade trainiertes Modell
   - Einzelvorhersage: Manuelle Eingabe der Features
   - Batch-Vorhersage: CSV-Upload
   - Visualisierung der Ergebnisse

## üìÅ Projektstruktur

```
ML-Projekt/
‚îÇ
‚îú‚îÄ‚îÄ wine+quality/
‚îÇ   ‚îú‚îÄ‚îÄ winequality-red.csv          # Rotwein-Datensatz
‚îÇ   ‚îú‚îÄ‚îÄ winequality-white.csv        # Wei√üwein-Datensatz
‚îÇ   ‚îî‚îÄ‚îÄ winequality.names            # Dokumentation
‚îÇ
‚îú‚îÄ‚îÄ wine_quality_analysis.ipynb      # Jupyter Notebook (Hauptanalyse)
‚îú‚îÄ‚îÄ wine_quality_app.py              # Streamlit Webanwendung
‚îú‚îÄ‚îÄ requirements.txt                 # Python-Abh√§ngigkeiten
‚îú‚îÄ‚îÄ README.md                        # Projektdokumentation
‚îÇ
‚îî‚îÄ‚îÄ (generierte Dateien nach Training)
    ‚îú‚îÄ‚îÄ wine_quality_models.pkl      # Gespeicherte Modelle (aus Notebook)
    ‚îî‚îÄ‚îÄ trained_model_*.pkl          # Modelle aus Streamlit App
```

## ü§ñ Modelle

### Regression (Vorhersage exakter Qualit√§tswerte)

| Modell | Test RMSE | Test MAE | Test R¬≤ | Empfehlung |
|--------|-----------|----------|---------|------------|
| **Random Forest (Tuned)** | ~0.58 | ~0.45 | ~0.50 | ‚≠ê Beste Balance |
| **Gradient Boosting (Tuned)** | ~0.59 | ~0.46 | ~0.49 | ‚≠ê Sehr gut |
| Random Forest | ~0.60 | ~0.47 | ~0.47 | Gut |
| Gradient Boosting | ~0.61 | ~0.48 | ~0.46 | Gut |
| Ridge Regression | ~0.65 | ~0.51 | ~0.38 | Baseline |
| Linear Regression | ~0.65 | ~0.51 | ~0.38 | Baseline |

### Klassifikation (Gut ‚â•6 vs Schlecht <6)

| Modell | Accuracy | Precision | Recall | F1-Score | AUC | Empfehlung |
|--------|----------|-----------|--------|----------|-----|------------|
| **Random Forest (Tuned)** | ~0.78 | ~0.80 | ~0.85 | ~0.82 | ~0.86 | ‚≠ê Beste Wahl |
| **Gradient Boosting (Tuned)** | ~0.77 | ~0.79 | ~0.84 | ~0.81 | ~0.85 | ‚≠ê Sehr gut |
| Random Forest | ~0.76 | ~0.78 | ~0.83 | ~0.80 | ~0.84 | Gut |
| Gradient Boosting | ~0.75 | ~0.77 | ~0.82 | ~0.79 | ~0.83 | Gut |
| Logistic Regression | ~0.73 | ~0.75 | ~0.80 | ~0.77 | ~0.80 | Baseline |

## üìà Ergebnisse

### Wichtigste Erkenntnisse:

1. **Top 5 wichtigste Features:**
   - Alkoholgehalt (alcohol)
   - Volatile S√§ure (volatile acidity)
   - Sulfate
   - Zitronens√§ure (citric acid)
   - Gesamtschwefeldioxid (total sulfur dioxide)

2. **Modellempfehlungen:**
   - **F√ºr Regression:** Random Forest Regressor (Tuned) - R¬≤ ‚âà 0.50
   - **F√ºr Klassifikation:** Random Forest Classifier (Tuned) - F1 ‚âà 0.82

3. **Performance:**
   - Regressionsmodelle erreichen R¬≤-Werte um 0.50, was f√ºr ein komplexes Qualit√§tsproblem mit vielen subjektiven Faktoren sehr gut ist
   - Klassifikationsmodelle erreichen F1-Scores um 0.82, was exzellent ist
   - Hyperparameter-Tuning verbessert die Performance um 5-10%

4. **Weintyp-Einfluss:**
   - Weintyp (Rot vs Wei√ü) hat moderaten Einfluss auf Qualit√§t
   - Beide Typen zeigen √§hnliche Qualit√§tsverteilungen
   - Chemische Eigenschaften sind wichtiger als der Weintyp

## üõ†Ô∏è Technologien

- **Python 3.8+**
- **Pandas** - Datenmanipulation
- **NumPy** - Numerische Operationen
- **Scikit-learn** - Machine Learning Modelle
- **Matplotlib & Seaborn** - Statische Visualisierungen
- **Plotly** - Interaktive Visualisierungen
- **Streamlit** - Webanwendung
- **Jupyter** - Notebooks f√ºr Analyse

## üìù Verwendete ML-Algorithmen

### Regression:
- Linear Regression
- Ridge Regression (L2 Regularisierung)
- Random Forest Regressor
- Gradient Boosting Regressor
- K-Nearest Neighbors Regressor
- Support Vector Regressor (SVR)

### Klassifikation:
- Logistic Regression
- Random Forest Classifier
- Gradient Boosting Classifier
- K-Nearest Neighbors Classifier
- Support Vector Classifier (SVC)

### Optimierung:
- RandomizedSearchCV f√ºr Hyperparameter-Tuning
- Cross-Validation (5-Fold)
- StandardScaler f√ºr Feature-Normalisierung

Ben Neunteufel
Klasse: 5AHITS
Datum: 14.12.2025
